{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fcc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985e07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73148363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seeds = list(np.arange(30))\n",
    "random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e3533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedfc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_intervals(dataset):\n",
    "    '''\n",
    "    Generate interval terminals, so that samples in each interval have:\n",
    "        interval_i = (timestamp >= terminal_i) and (timestamp < terminal_{i+1})\n",
    "\n",
    "    Args:\n",
    "        dataset (chr): Assuming only Backblaze (b) and Google (g) datasets exists\n",
    "    '''\n",
    "    if dataset == 'g':\n",
    "        # time unit in Google: millisecond, tracing time: 29 days\n",
    "        start_time = 604046279\n",
    "        unit_period = 24 * 60 * 60 * 1000 * 1000  # unit period: one day\n",
    "        end_time = start_time + 28*unit_period\n",
    "    elif dataset == 'b':\n",
    "        # time unit in Backblaze: month, tracing time: one year (12 months)\n",
    "        start_time = 1\n",
    "        unit_period = 1  # unit period: one month\n",
    "        end_time = start_time + 12*unit_period\n",
    "    \n",
    "    # add one unit for the open-end of range function\n",
    "    terminals = [i for i in range(start_time, end_time+unit_period, unit_period)]\n",
    "\n",
    "    return terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d205719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_natural_chunks(features, labels, terminals):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(terminals) - 1):\n",
    "        idx = np.logical_and(features[:, 0] >= terminals[i], features[:, 0] < terminals[i + 1])\n",
    "        feature_list.append(features[idx][:, 1:])\n",
    "        label_list.append(labels[idx])\n",
    "    return feature_list, label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d06b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(training_features, training_labels, ratio=10):\n",
    "    #return training_features, training_labels\n",
    "\n",
    "    idx_true = np.where(training_labels == True)[0]\n",
    "    idx_false = np.where(training_labels == False)[0]\n",
    "    #print('Before dowmsampling:', len(idx_true), len(idx_false))\n",
    "    idx_false_resampled = resample(idx_false, n_samples=len(idx_true)*ratio, replace=False, random_state = random_seed)\n",
    "    idx_resampled = np.concatenate([idx_false_resampled, idx_true])\n",
    "    idx_resampled.sort()\n",
    "    resampled_features = training_features[idx_resampled]\n",
    "    resampled_labels = training_labels[idx_resampled]\n",
    "    #print('After dowmsampling:', len(idx_true), len(idx_false_resampled))\n",
    "    return resampled_features, resampled_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584a6f0",
   "metadata": {},
   "source": [
    "Feature Importance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5795ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_extraction(model, features_input):\n",
    "    \n",
    "    # extract features and their importances\n",
    "    \n",
    "    feature_importance_ranking = model.feature_importances_\n",
    "    zipped_features = list(zip(feature_importance_ranking, features_input))\n",
    "    sorted_features_zip = sorted(zipped_features, key = lambda x: x[0], reverse = True)\n",
    "    \n",
    "    # extract mean of importances\n",
    "    \n",
    "    importances = [i[0] for i in sorted_features_zip]\n",
    "    mean_importances = np.mean(importances)\n",
    "    \n",
    "    # extract most important features and return\n",
    "    \n",
    "    most_important_features = [i[1] for i in sorted_features_zip if i[0]>= mean_importances]\n",
    "    \n",
    "    return most_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ecbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_non_important_features(features_array, features_names, important_features_names):\n",
    "    # transform array into dataframe and attach features\n",
    "    df_features = pd.DataFrame(np.array(features_array), columns = features_names)\n",
    "    \n",
    "    # filter out columns with non-relevant features\n",
    "    df_important_features = df_features[df_features.columns[~df_features.columns.isin(important_features)==0]]\n",
    "    \n",
    "    # transform dataframe with only into features back into array\n",
    "    important_features_array = df_important_features.to_numpy()\n",
    "    \n",
    "    return important_features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70a2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_preprocessing(DATASET_PATH, dataset):\n",
    "    \n",
    "    if(dataset=='b'):\n",
    "        \n",
    "        print('Data Reading and Preprocessing')\n",
    "        \n",
    "        # set data paths and columns names\n",
    "        features_disk_failure = ['smart_1_raw', 'smart_4_raw', 'smart_5_raw', 'smart_7_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw', 'smart_193_raw', 'smart_194_raw', 'smart_197_raw', 'smart_199_raw', \n",
    "                         'smart_4_raw_diff', 'smart_5_raw_diff', 'smart_9_raw_diff', 'smart_12_raw_diff', 'smart_187_raw_diff', 'smart_193_raw_diff', 'smart_197_raw_diff', 'smart_199_raw_diff']\n",
    "        columns = ['serial_number', 'date'] + features_disk_failure + ['label']\n",
    "        \n",
    "        # read dataset\n",
    "        df = pd.read_csv(DATASET_PATH_DISK, header=None, dtype = 'str').iloc[1:,1:]\n",
    "        df.columns = columns\n",
    "        \n",
    "        # ignore serial number\n",
    "        df = df[df.columns[1:]]\n",
    "        \n",
    "        for feature in features_disk_failure:\n",
    "            df[feature] = df[feature].astype(float)\n",
    "\n",
    "\n",
    "        d = {'True': True, 'False': False}\n",
    "        df['label'] = df['label'].map(d)\n",
    "\n",
    "        df['label'].unique()\n",
    "\n",
    "        # transform date to date time\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "        # divide on weeks\n",
    "        df['date'] = pd.Series(pd.DatetimeIndex(df['date']).day_of_year)\n",
    "        \n",
    "        print('Features and Labels Computing')\n",
    "        \n",
    "        # features and labels extraction and computation\n",
    "        features = df[df.columns[:-1]].to_numpy()\n",
    "        labels = df[df.columns[-1]].to_numpy()\n",
    "        feature_list, label_list = obtain_natural_chunks(features, labels, obtain_intervals('b'))\n",
    "        \n",
    "    elif(dataset=='g'):\n",
    "        \n",
    "        print('Data Reading and Preprocessing')\n",
    "        \n",
    "        # set data paths and columns names\n",
    "        features_job_failure = ['User ID', 'Job Name', 'Scheduling Class',\n",
    "                   'Num Tasks', 'Priority', 'Diff Machine', 'CPU Requested', 'Mem Requested', 'Disk Requested',\n",
    "                   'Avg CPU', 'Avg Mem', 'Avg Disk', 'Std CPU', 'Std Mem', 'Std Disk']\n",
    "        columns_initial = ['Job ID', 'Status', 'Start Time', 'End Time'] + features_job_failure\n",
    "        \n",
    "        # read dataset\n",
    "        df = pd.read_csv(DATASET_PATH, header=None)\n",
    "        df.columns = columns_initial\n",
    "        df = df.tail(-1)\n",
    "        # ignore Job ID\n",
    "        df = df.drop(['Job ID'], axis = 1)\n",
    "        columns = features_job_failure\n",
    "\n",
    "        include_end_time = False\n",
    "        \n",
    "        print('Features and Labels Preprocessing')\n",
    "        \n",
    "        # features and labels preprocessing\n",
    "        features = df[(['Start Time']+ features_job_failure)].to_numpy()\n",
    "        labels = (df['Status']==3).to_numpy()\n",
    "\n",
    "        # FEATURES PREPROCESSING\n",
    "        offset = (1 if include_end_time else 0)\n",
    "\n",
    "        # ENCODE USER ID\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features[:, 1+offset] = le.fit_transform(features[:, 1+offset])\n",
    "\n",
    "        # ENCODE JOB NAME\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        features[:, 2+offset] = le.fit_transform(features[:, 2+offset])\n",
    "\n",
    "        features = features.astype(float)\n",
    "        \n",
    "        print('Features and Labels Computing')\n",
    "        \n",
    "        # features and labels extraction and computation\n",
    "        feature_list, label_list = obtain_natural_chunks(features, labels, obtain_intervals('g'))\n",
    "        \n",
    "    else:\n",
    "        print('Incorrect Dataset')\n",
    "    \n",
    "    return feature_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "710cb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_drift_detection(reference_data, testing_data):\n",
    "    \n",
    "    # extract distributions from reference and testing data\n",
    "    \n",
    "    distribution_extraction_time_start = time.time()\n",
    "    distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
    "    plt.close()\n",
    "    distribution_extraction_time_end = time.time() - distribution_extraction_time_start\n",
    "    # apply KS statistical test\n",
    "    \n",
    "    ks_test_time_start = time.time()\n",
    "    stat_test = stats.kstest\n",
    "    v, p = stat_test(distribution_reference, distribution_test)\n",
    "    ks_test_time_end = time.time() - ks_test_time_start\n",
    "    # check if drift\n",
    "    \n",
    "    if(p<0.05):\n",
    "        drift_alert = 1\n",
    "    else:\n",
    "        drift_alert = 0\n",
    "\n",
    "    return drift_alert, distribution_extraction_time_end, ks_test_time_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476062c",
   "metadata": {},
   "source": [
    "Feature Importance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe24da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features_extraction(model, features_input):\n",
    "    \n",
    "    # extract features and their importances\n",
    "    \n",
    "    feature_importance_ranking = model.feature_importances_\n",
    "    zipped_features = list(zip(feature_importance_ranking, features_input))\n",
    "    sorted_features_zip = sorted(zipped_features, key = lambda x: x[0], reverse = True)\n",
    "    \n",
    "    # extract mean of importances\n",
    "    \n",
    "    importances = [i[0] for i in sorted_features_zip]\n",
    "    mean_importances = np.mean(importances)\n",
    "    \n",
    "    # extract most important features and return\n",
    "    \n",
    "    most_important_features = [i[1] for i in sorted_features_zip if i[0]>= mean_importances]\n",
    "    \n",
    "    return most_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbeb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_non_important_features(features_array, features_names, important_features_names):\n",
    "    # transform array into dataframe and attach features\n",
    "    df_features = pd.DataFrame(np.array(features_array), columns = features_names)\n",
    "    \n",
    "    # filter out columns with non-relevant features\n",
    "    df_important_features = df_features[df_features.columns[~df_features.columns.isin(important_features)==0]]\n",
    "    \n",
    "    # transform dataframe with only into features back into array\n",
    "    important_features_array = df_important_features.to_numpy()\n",
    "    \n",
    "    return important_features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7a667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb3283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10465761",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04462306",
   "metadata": {},
   "source": [
    "# Extracting Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed70b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH_DISK = '../../../Documents/phd_related/AIOps_disk_failure_prediction/raw_data_2015_2017/disk_2015_complete.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7a415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f2127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Reading and Preprocessing\n",
      "Features and Labels Computing\n"
     ]
    }
   ],
   "source": [
    "feature_list, label_list = features_labels_preprocessing(DATASET_PATH_DISK, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc593c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9478b377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chunks = len(feature_list)\n",
    "num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332a6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b23eb9f4",
   "metadata": {},
   "source": [
    "## True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426d85c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_testing_labels = np.hstack(label_list[num_chunks//2:])\n",
    "true_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2567e51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83460"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01d405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbb76349",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER_SEARCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10a0b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_rf = {\n",
    "            'n_estimators': stats.randint(1e1, 1e2),\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'max_depth': [int(x) for x in np.linspace(10, 110, num=6)] + [None],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 4, 8],\n",
    "            'class_weight':['balanced', None],\n",
    "            'bootstrap': [True, False]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f64b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6378a4e9",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b6f875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd33e31",
   "metadata": {},
   "source": [
    "# Periodic Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "146a3cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN TRAINING 1782\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:32<02:42, 32.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_depth=10, max_features='log2',\n",
      "                       n_estimators=49, random_state=0)\n",
      "Training\n",
      "Length of Training 11099\n",
      "LEN TRAINING 2145\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [01:13<02:30, 37.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=10,\n",
      "                       max_features='log2', min_samples_leaf=2,\n",
      "                       min_samples_split=8, n_estimators=60, random_state=0)\n",
      "Training\n",
      "Length of Training 13244\n",
      "LEN TRAINING 2519\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=10,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=96,\n",
      "                       random_state=0)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:56<01:59, 39.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 15763\n",
      "LEN TRAINING 2871\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=90,\n",
      "                       max_features='log2', min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=77, random_state=0)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [02:45<01:27, 43.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 18634\n",
      "LEN TRAINING 3157\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=110,\n",
      "                       min_samples_leaf=4, n_estimators=63, random_state=0)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [03:36<00:46, 46.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 21791\n",
      "LEN TRAINING 3443\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(criterion='entropy', max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=8, n_estimators=71, random_state=0)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:31<00:00, 45.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 25234\n",
      "Random Seed 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN TRAINING 1782\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:34<02:54, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
      "                       min_samples_leaf=2, n_estimators=62, random_state=1)\n",
      "Training\n",
      "Length of Training 27016\n",
      "LEN TRAINING 2145\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [01:17<02:38, 39.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, min_samples_leaf=2, min_samples_split=8,\n",
      "                       n_estimators=21, random_state=1)\n",
      "Training\n",
      "Length of Training 29161\n",
      "LEN TRAINING 2519\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:58<02:00, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_depth=10, max_features='log2',\n",
      "                       min_samples_split=4, n_estimators=19, random_state=1)\n",
      "Training\n",
      "Length of Training 31680\n",
      "LEN TRAINING 2871\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [02:45<01:25, 42.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=70, min_samples_leaf=2, n_estimators=49,\n",
      "                       random_state=1)\n",
      "Training\n",
      "Length of Training 34551\n",
      "LEN TRAINING 3157\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [03:36<00:45, 45.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=10,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=38,\n",
      "                       random_state=1)\n",
      "Training\n",
      "Length of Training 37708\n",
      "LEN TRAINING 3443\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:30<00:00, 45.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=110,\n",
      "                       max_features='log2', min_samples_leaf=2, n_estimators=31,\n",
      "                       random_state=1)\n",
      "Training\n",
      "Length of Training 41151\n",
      "Random Seed 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN TRAINING 1782\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(max_depth=110, n_estimators=99, random_state=2)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:33<02:48, 33.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 42933\n",
      "LEN TRAINING 2145\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [01:12<02:27, 36.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=90, min_samples_leaf=2,\n",
      "                       n_estimators=41, random_state=2)\n",
      "Training\n",
      "Length of Training 45078\n",
      "LEN TRAINING 2519\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:55<01:57, 39.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=70,\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=35,\n",
      "                       random_state=2)\n",
      "Training\n",
      "Length of Training 47597\n",
      "LEN TRAINING 2871\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=63, random_state=2)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [02:45<01:27, 43.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 50468\n",
      "LEN TRAINING 3157\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=50,\n",
      "                       min_samples_leaf=2, n_estimators=93, random_state=2)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [03:39<00:47, 47.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 53625\n",
      "LEN TRAINING 3443\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:37<00:00, 46.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=110, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=39, random_state=2)\n",
      "Training\n",
      "Length of Training 57068\n",
      "Random Seed 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN TRAINING 1782\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:36<03:04, 36.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, min_samples_leaf=2, n_estimators=13,\n",
      "                       random_state=3)\n",
      "Training\n",
      "Length of Training 58850\n",
      "LEN TRAINING 2145\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [01:19<02:41, 40.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=110, max_features='log2',\n",
      "                       min_samples_leaf=4, n_estimators=11, random_state=3)\n",
      "Training\n",
      "Length of Training 60995\n",
      "LEN TRAINING 2519\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [02:06<02:09, 43.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=90,\n",
      "                       max_features='log2', min_samples_leaf=2, n_estimators=61,\n",
      "                       random_state=3)\n",
      "Training\n",
      "Length of Training 63514\n",
      "LEN TRAINING 2871\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [02:57<01:32, 46.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_depth=70, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=24, random_state=3)\n",
      "Training\n",
      "Length of Training 66385\n",
      "LEN TRAINING 3157\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=69, random_state=3)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [03:52<00:49, 49.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 69542\n",
      "LEN TRAINING 3443\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=30, max_features='log2', min_samples_leaf=4,\n",
      "                       min_samples_split=8, n_estimators=96, random_state=3)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:51<00:00, 48.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 72985\n",
      "Random Seed 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN TRAINING 1782\n",
      "Finding Hyperparameters\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=90,\n",
      "                       max_features='log2', min_samples_split=4,\n",
      "                       n_estimators=90, random_state=4)\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:38<03:10, 38.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training 74767\n",
      "LEN TRAINING 2145\n",
      "Finding Hyperparameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [01:01<05:07, 61.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 62\u001b[0m\n\u001b[1;32m     56\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model,\n\u001b[1;32m     57\u001b[0m                                            param_distributions \u001b[38;5;241m=\u001b[39m param_dist_rf,\n\u001b[1;32m     58\u001b[0m                                            n_iter\u001b[38;5;241m=\u001b[39mN_ITER_SEARCH,\n\u001b[1;32m     59\u001b[0m                                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m                                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinding Hyperparameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_features_downsampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels_downsampling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m update_model \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(update_model)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:340\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    Build a forest of trees from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/base.py:602\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[0;32m--> 602\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    603\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    604\u001b[0m     )\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/base.py:169\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03mGet parameters for this estimator.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Parameter names mapped to their values.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_param_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    170\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/base.py:138\u001b[0m, in \u001b[0;36mBaseEstimator._get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    134\u001b[0m init_signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Consider the constructor parameters excluding 'self'\u001b[39;00m\n\u001b[1;32m    136\u001b[0m parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    137\u001b[0m     p\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43minit_signature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m p\u001b[38;5;241m.\u001b[39mVAR_KEYWORD\n\u001b[1;32m    140\u001b[0m ]\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m p\u001b[38;5;241m.\u001b[39mVAR_POSITIONAL:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3030\u001b[0m, in \u001b[0;36mSignature.parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   3027\u001b[0m                                     follow_wrapper_chains\u001b[38;5;241m=\u001b[39mfollow_wrapped,\n\u001b[1;32m   3028\u001b[0m                                     \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[0;32m-> 3030\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreturn_annotation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for random_seed in random_seeds:\n",
    "\n",
    "    print('Random Seed', random_seed)\n",
    "    \n",
    "    total_time_training = 0\n",
    "    predictions_test_fh = []\n",
    "    \n",
    "    partial_roc_auc_fh = []\n",
    "    \n",
    "    \n",
    "\n",
    "    begin_total_fh = time.time()\n",
    "\n",
    "    total_train_fh = 0 \n",
    "    total_hyperparam_fh = 0\n",
    "    total_test_fh = 0\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "\n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "\n",
    "\n",
    "        # scaler and downsampling for training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features = update_scaler.fit_transform(training_features)\n",
    "        training_features_downsampling, training_labels_downsampling = downsampling(training_features, training_labels)\n",
    "\n",
    "        print('LEN TRAINING', len(training_features_downsampling))\n",
    "        length_training_fh = length_training_fh + len(training_features_downsampling)\n",
    "        \n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        # scaling testing features\n",
    "        testing_features = update_scaler.transform(testing_features)\n",
    "\n",
    "        \n",
    "        \n",
    "        # training model\n",
    "        begin_train_fh = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        begin_hyperparam_tunning_update = time.time()\n",
    "        model = RandomForestClassifier(random_state = random_seed)\n",
    "        random_search = RandomizedSearchCV(model,\n",
    "                                                   param_distributions = param_dist_rf,\n",
    "                                                   n_iter=N_ITER_SEARCH,\n",
    "                                                   scoring='roc_auc',\n",
    "                                                   cv=4, n_jobs=1)\n",
    "        print('Finding Hyperparameters')\n",
    "        random_search.fit(training_features_downsampling, training_labels_downsampling)\n",
    "\n",
    "        update_model = random_search.best_estimator_\n",
    "        print(update_model)\n",
    "\n",
    "        end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "\n",
    "        print('Training')\n",
    "        update_model.fit(training_features_downsampling, training_labels_downsampling)\n",
    "        end_train_fh = time.time() - begin_train_fh\n",
    "        \n",
    "        \n",
    "        total_hyperparam_fh = total_hyperparam_fh + end_hyperparam_tunning_update\n",
    "        total_train_fh = total_train_fh + end_train_fh\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data\n",
    "        begin_test_fh = time.time()\n",
    "        predictions_test_updated = update_model.predict(testing_features)\n",
    "        end_test_fh = time.time() - begin_test_fh\n",
    "        total_test_fh = total_test_fh + end_test_fh\n",
    "\n",
    "\n",
    "        partial_roc_auc_fh.append(roc_auc_score(testing_labels, predictions_test_updated))\n",
    "        predictions_test_fh = np.concatenate([predictions_test_fh, predictions_test_updated])\n",
    "\n",
    "        training_features = np.vstack(feature_list[0: i+1])\n",
    "        training_labels = np.hstack(label_list[0: i+1])\n",
    "        \n",
    "        print('Length of Training', length_training_fh)\n",
    "\n",
    "    end_total_fh = time.time() - begin_total_fh\n",
    "    \n",
    "    \n",
    "    df_results_periodic_fh = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts', 'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Label_Costs'])\n",
    "    df_results_periodic_fh.loc[0] = [random_seed, 'periodic-sw', str(int(num_chunks//2)) + '/' + str(int(num_chunks//2)), partial_roc_auc_fh, np.mean(partial_roc_auc_fh), roc_auc_score(true_testing_labels, predictions_test_fh), predictions_test_fh, true_testing_labels,  total_train_fh, total_hyperparam_fh, total_test_fh, np.ones(int(num_chunks//2), dtype=int), len(true_testing_labels)]\n",
    "\n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_periodic_fh])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/periodic_fh_model_backblaze_data_green.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96539107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cdc0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>Drifts</th>\n",
       "      <th>ROC_AUC_Batch</th>\n",
       "      <th>ROC_AUC_BATCH_MEAN</th>\n",
       "      <th>ROC_AUC_Total</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Testing_Labels</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Hyperparam_Tunning_Time</th>\n",
       "      <th>Test_Time</th>\n",
       "      <th>Drifts_Detected</th>\n",
       "      <th>Label_Costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>periodic-sw</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.9224351517780277, 0.954291838192767, 0.9828...</td>\n",
       "      <td>0.963134</td>\n",
       "      <td>0.961766</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>288.414711</td>\n",
       "      <td>287.328930</td>\n",
       "      <td>0.305474</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>periodic-sw</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.937405939683103, 0.9839566393358964, 0.9823...</td>\n",
       "      <td>0.970212</td>\n",
       "      <td>0.970026</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>293.298577</td>\n",
       "      <td>292.287884</td>\n",
       "      <td>0.262072</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>periodic-sw</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.9073920729743763, 0.9399112884020004, 0.982...</td>\n",
       "      <td>0.958032</td>\n",
       "      <td>0.956053</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>270.606751</td>\n",
       "      <td>269.576997</td>\n",
       "      <td>0.278546</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>periodic-sw</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.937405939683103, 0.967804834484401, 0.96719...</td>\n",
       "      <td>0.964976</td>\n",
       "      <td>0.964259</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>270.132688</td>\n",
       "      <td>269.617659</td>\n",
       "      <td>0.137549</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>periodic-sw</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.9378396850745583, 0.969286905045419, 0.9828...</td>\n",
       "      <td>0.968188</td>\n",
       "      <td>0.967431</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>276.899207</td>\n",
       "      <td>275.992308</td>\n",
       "      <td>0.245746</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>periodic-sw</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.9369721942916479, 0.9104995236961181, 0.982...</td>\n",
       "      <td>0.961227</td>\n",
       "      <td>0.958919</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>291.450793</td>\n",
       "      <td>290.608667</td>\n",
       "      <td>0.189059</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_Seed        Model Drifts  \\\n",
       "0            0  periodic-sw    6/6   \n",
       "1            1  periodic-sw    6/6   \n",
       "2            0  periodic-sw    6/6   \n",
       "3            1  periodic-sw    6/6   \n",
       "4            2  periodic-sw    6/6   \n",
       "5            3  periodic-sw    6/6   \n",
       "\n",
       "                                       ROC_AUC_Batch  ROC_AUC_BATCH_MEAN  \\\n",
       "0  [0.9224351517780277, 0.954291838192767, 0.9828...            0.963134   \n",
       "1  [0.937405939683103, 0.9839566393358964, 0.9823...            0.970212   \n",
       "2  [0.9073920729743763, 0.9399112884020004, 0.982...            0.958032   \n",
       "3  [0.937405939683103, 0.967804834484401, 0.96719...            0.964976   \n",
       "4  [0.9378396850745583, 0.969286905045419, 0.9828...            0.968188   \n",
       "5  [0.9369721942916479, 0.9104995236961181, 0.982...            0.961227   \n",
       "\n",
       "   ROC_AUC_Total                                        Predictions  \\\n",
       "0       0.961766  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1       0.970026  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2       0.956053  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3       0.964259  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4       0.967431  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5       0.958919  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                 True_Testing_Labels  Train_Time  \\\n",
       "0  [False, False, False, False, False, False, Fal...  288.414711   \n",
       "1  [False, False, False, False, False, False, Fal...  293.298577   \n",
       "2  [False, False, False, False, False, False, Fal...  270.606751   \n",
       "3  [False, False, False, False, False, False, Fal...  270.132688   \n",
       "4  [False, False, False, False, False, False, Fal...  276.899207   \n",
       "5  [False, False, False, False, False, False, Fal...  291.450793   \n",
       "\n",
       "   Hyperparam_Tunning_Time  Test_Time     Drifts_Detected  Label_Costs  \n",
       "0               287.328930   0.305474  [1, 1, 1, 1, 1, 1]        83460  \n",
       "1               292.287884   0.262072  [1, 1, 1, 1, 1, 1]        83460  \n",
       "2               269.576997   0.278546  [1, 1, 1, 1, 1, 1]        83460  \n",
       "3               269.617659   0.137549  [1, 1, 1, 1, 1, 1]        83460  \n",
       "4               275.992308   0.245746  [1, 1, 1, 1, 1, 1]        83460  \n",
       "5               290.608667   0.189059  [1, 1, 1, 1, 1, 1]        83460  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edbe32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1b492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4e6f6a9",
   "metadata": {},
   "source": [
    "# Build Drift Detection based Model Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822c81b",
   "metadata": {},
   "source": [
    "### KS on all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475f69c",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5b1c2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc733ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=30, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=95, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:38<03:12, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6]\n",
      "LEN TRAINING 2145\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(bootstrap=False, max_depth=90, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=95,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [01:20<02:42, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "LEN TRAINING 2519\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=10, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=89,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [02:13<02:18, 46.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "LEN TRAINING 2871\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=30,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=67,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [03:04<01:35, 47.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=110, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=30,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [03:58<00:50, 50.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "LEN TRAINING 3443\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=50, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=65,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [04:56<00:00, 49.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Random Seed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=63,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:38<03:14, 38.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6]\n",
      "LEN TRAINING 2145\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=13,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [01:28<03:01, 45.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "LEN TRAINING 2519\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=52,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [02:18<02:22, 47.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "LEN TRAINING 2871\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=90, min_samples_leaf=2, min_samples_split=4,\n",
      "                       n_estimators=63, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [03:09<01:37, 48.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=50,\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=50,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [04:04<00:50, 50.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "LEN TRAINING 3443\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_depth=30,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=55,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [05:04<00:00, 50.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Random Seed: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=90, min_samples_split=8,\n",
      "                       n_estimators=75, random_state=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:36<03:02, 36.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6]\n",
      "LEN TRAINING 2145\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(class_weight='balanced', min_samples_leaf=2,\n",
      "                       min_samples_split=8, n_estimators=53, random_state=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [01:17<02:35, 38.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "LEN TRAINING 2519\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=110,\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=32,\n",
      "                       random_state=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [02:01<02:04, 41.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "LEN TRAINING 2871\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(bootstrap=False, max_features='log2', min_samples_leaf=2,\n",
      "                       n_estimators=83, random_state=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [02:51<01:29, 44.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(class_weight='balanced', min_samples_leaf=2,\n",
      "                       min_samples_split=8, n_estimators=53, random_state=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [03:42<00:47, 47.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "LEN TRAINING 3443\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=110,\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=32,\n",
      "                       random_state=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [04:39<00:00, 46.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Random Seed: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 84\u001b[0m\n\u001b[1;32m     76\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state \u001b[38;5;241m=\u001b[39m random_seed)\n\u001b[1;32m     77\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model,\n\u001b[1;32m     78\u001b[0m                                            param_distributions \u001b[38;5;241m=\u001b[39m param_dist_rf,\n\u001b[1;32m     79\u001b[0m                                            n_iter\u001b[38;5;241m=\u001b[39mN_ITER_SEARCH,\n\u001b[1;32m     80\u001b[0m                                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     81\u001b[0m                                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m random_seed)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_features_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m update_model_ks_all \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     90\u001b[0m end_hyperparam_tunning_update \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m begin_hyperparam_tunning_update\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:178\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 178\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_random_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# Need to validate separately here.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# csr.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1226\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmtrand\u001b[38;5;241m.\u001b[39m_rand\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState):\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "File \u001b[0;32mmtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:129\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:533\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.BitGenerator.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mbit_generator.pyx:302\u001b[0m, in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/random.py:802\u001b[0m, in \u001b[0;36mSystemRandom.getrandbits\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of bits must be non-negative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    801\u001b[0m numbytes \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m7\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m                       \u001b[38;5;66;03m# bits / 8 and rounded up\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_bytes(_urandom(numbytes))\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m>>\u001b[39m (numbytes \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m-\u001b[39m k)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_training_batches_list = list(range(0, num_chunks//2))\n",
    "\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "\n",
    "    print('Random Seed:', random_seed)\n",
    "    necessary_label_annotation_effort = 0\n",
    "    total_time_training = 0\n",
    "    no_necessary_retrainings = 0\n",
    "    lengths_training_ks_all = []\n",
    "    partial_roc_auc_ks_all_model = []\n",
    "    \n",
    "    \n",
    "    predictions_test_ks_all_model = []\n",
    "    \n",
    "    \n",
    "\n",
    "    total_train_fh_all = 0\n",
    "    total_hyperparam_fh_ks_all = 0\n",
    "    total_test_time_ks_all = 0\n",
    "    \n",
    "    total_drift_detection_time = 0\n",
    "    total_distribution_extraction_time = 0\n",
    "    total_stat_test_time = 0\n",
    "    \n",
    "    \n",
    "    detected_drifts = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "    \n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        \n",
    "        # init drift alert\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "            current_training_batches_list = initial_training_batches_list.copy()\n",
    "            print('Initial Training Batches', current_training_batches_list)\n",
    "\n",
    "        #print('Training for Model before Scaling', training_features)\n",
    "        \n",
    "\n",
    "        # scaler and downsampling on training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features_model = update_scaler.fit_transform(training_features)\n",
    "        training_features_model, training_labels_model = downsampling(training_features_model, training_labels)\n",
    "\n",
    "        print('LEN TRAINING', len(training_features_model))\n",
    "        \n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        \n",
    "        # scaling testing features\n",
    "        testing_features_model = update_scaler.transform(testing_features)\n",
    "        testing_labels_model = testing_labels\n",
    "\n",
    "\n",
    "         # training model\n",
    "        begin_train_fh_ks_all = time.time()\n",
    "\n",
    "\n",
    "        if(i==num_chunks//2 or need_to_retrain == 1):\n",
    "            print('RETRAINING MODEL')\n",
    "            \n",
    "            begin_train_fh_ks_all = time.time()\n",
    "        \n",
    "            begin_hyperparam_tunning_update = time.time()\n",
    "            model = RandomForestClassifier(random_state = random_seed)\n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                                       param_distributions = param_dist_rf,\n",
    "                                                       n_iter=N_ITER_SEARCH,\n",
    "                                                       scoring='roc_auc',\n",
    "                                                       cv=4, n_jobs=1, random_state = random_seed)\n",
    "\n",
    "            \n",
    "            random_search.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            update_model_ks_all = random_search.best_estimator_\n",
    "            \n",
    "            \n",
    "\n",
    "            end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "            \n",
    "            total_hyperparam_fh_ks_all = total_hyperparam_fh_ks_all + end_hyperparam_tunning_update\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            update_model_ks_all.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            end_train_fh_ks_all = time.time() - begin_train_fh_ks_all\n",
    "        \n",
    "            total_train_fh_all = total_train_fh_all + end_train_fh_ks_all\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data\n",
    "        \n",
    "        begin_test_time_ks_all = time.time()\n",
    "        predictions_test_updated = update_model_ks_all.predict(testing_features_model)\n",
    "        \n",
    "        end_test_time_ks_all = time.time() - begin_test_time_ks_all\n",
    "        total_test_time_ks_all = total_test_time_ks_all + end_test_time_ks_all\n",
    "\n",
    "        partial_roc_auc_ks_all_model.append(roc_auc_score(testing_labels_model, predictions_test_updated))\n",
    "        \n",
    "        predictions_test_ks_all_model = np.concatenate([predictions_test_ks_all_model, predictions_test_updated])\n",
    "        \n",
    "        \n",
    "        print('Predictions Test Batch', len(predictions_test_updated))\n",
    "        print('Prediction Test All', len(predictions_test_ks_all_model))\n",
    "        \n",
    "        \n",
    "        # Drift Detection\n",
    "        \n",
    "        need_to_retrain = 0\n",
    "        \n",
    "        print('MODEL', update_model_ks_all)\n",
    "        \n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(training_features_model, testing_features_model)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "        \n",
    "        detected_drifts.append(drift_alert)\n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "        if(drift_alert==1):\n",
    "        \n",
    "            need_to_retrain = 1\n",
    "            drift_alert = 0\n",
    "\n",
    "       \n",
    "       \n",
    "            \n",
    "            print('CHANGE OF TRAINING')\n",
    "\n",
    "            no_necessary_retrainings = no_necessary_retrainings + 1\n",
    "            necessary_label_annotation_effort = necessary_label_annotation_effort + len(testing_labels)\n",
    "\n",
    "            # add new data to the training for full history approach\n",
    "            current_training_batches_list.append(i)\n",
    "                    \n",
    "            \n",
    "            training_features_list_updated = [feature_list[i] for i in current_training_batches_list]\n",
    "            training_labels_list_updated = [label_list[i] for i in current_training_batches_list]\n",
    "        \n",
    "            training_features = np.vstack(training_features_list_updated)\n",
    "            training_labels = np.hstack(training_labels_list_updated)\n",
    "\n",
    "        \n",
    "        print('Current Training Batches',current_training_batches_list)\n",
    "    \n",
    "    \n",
    "    df_results_ks_all_model = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts_Overall',  'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Drift_Detection_Total_Time', 'Distribution_Extraction_Time', 'Statistical_Test_Time', 'Label_Costs'])\n",
    "    df_results_ks_all_model.loc[0] = [random_seed, 'KS_ALL', str(no_necessary_retrainings)+'/'+str(len(detected_drifts)), partial_roc_auc_ks_all_model, np.mean(partial_roc_auc_ks_all_model), roc_auc_score(true_testing_labels, predictions_test_ks_all_model), predictions_test_ks_all_model, true_testing_labels, total_train_fh_all, total_hyperparam_fh_ks_all, total_test_time_ks_all, detected_drifts, total_drift_detection_time, total_distribution_extraction_time, total_stat_test_time, necessary_label_annotation_effort]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_ks_all_model])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/ks_all_fh_model_disk_data_green.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c5c0bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>Drifts_Overall</th>\n",
       "      <th>ROC_AUC_Batch</th>\n",
       "      <th>ROC_AUC_BATCH_MEAN</th>\n",
       "      <th>ROC_AUC_Total</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Testing_Labels</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Hyperparam_Tunning_Time</th>\n",
       "      <th>Test_Time</th>\n",
       "      <th>Drifts_Detected</th>\n",
       "      <th>Drift_Detection_Total_Time</th>\n",
       "      <th>Distribution_Extraction_Time</th>\n",
       "      <th>Statistical_Test_Time</th>\n",
       "      <th>Label_Costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KS_ALL</td>\n",
       "      <td>5/6</td>\n",
       "      <td>[0.9224351517780277, 0.95450872656755, 0.98253...</td>\n",
       "      <td>0.963122</td>\n",
       "      <td>0.961754</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>291.762608</td>\n",
       "      <td>290.709915</td>\n",
       "      <td>0.276728</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0]</td>\n",
       "      <td>4.042772</td>\n",
       "      <td>4.041776</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>69507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KS_ALL</td>\n",
       "      <td>5/6</td>\n",
       "      <td>[0.937405939683103, 0.9252054060490593, 0.9817...</td>\n",
       "      <td>0.960324</td>\n",
       "      <td>0.958769</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>299.695743</td>\n",
       "      <td>299.015962</td>\n",
       "      <td>0.190906</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0]</td>\n",
       "      <td>3.986231</td>\n",
       "      <td>3.985239</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>69507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>KS_ALL</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.9229773335173466, 0.9826191610247338, 0.982...</td>\n",
       "      <td>0.967957</td>\n",
       "      <td>0.967274</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>274.669569</td>\n",
       "      <td>273.880413</td>\n",
       "      <td>0.220179</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>4.029029</td>\n",
       "      <td>4.028030</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_Seed   Model Drifts_Overall  \\\n",
       "0            0  KS_ALL            5/6   \n",
       "1            1  KS_ALL            5/6   \n",
       "2            2  KS_ALL            6/6   \n",
       "\n",
       "                                       ROC_AUC_Batch  ROC_AUC_BATCH_MEAN  \\\n",
       "0  [0.9224351517780277, 0.95450872656755, 0.98253...            0.963122   \n",
       "1  [0.937405939683103, 0.9252054060490593, 0.9817...            0.960324   \n",
       "2  [0.9229773335173466, 0.9826191610247338, 0.982...            0.967957   \n",
       "\n",
       "   ROC_AUC_Total                                        Predictions  \\\n",
       "0       0.961754  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1       0.958769  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2       0.967274  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                 True_Testing_Labels  Train_Time  \\\n",
       "0  [False, False, False, False, False, False, Fal...  291.762608   \n",
       "1  [False, False, False, False, False, False, Fal...  299.695743   \n",
       "2  [False, False, False, False, False, False, Fal...  274.669569   \n",
       "\n",
       "   Hyperparam_Tunning_Time  Test_Time     Drifts_Detected  \\\n",
       "0               290.709915   0.276728  [1, 1, 1, 1, 1, 0]   \n",
       "1               299.015962   0.190906  [1, 1, 1, 1, 1, 0]   \n",
       "2               273.880413   0.220179  [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "   Drift_Detection_Total_Time  Distribution_Extraction_Time  \\\n",
       "0                    4.042772                      4.041776   \n",
       "1                    3.986231                      3.985239   \n",
       "2                    4.029029                      4.028030   \n",
       "\n",
       "   Statistical_Test_Time  Label_Costs  \n",
       "0               0.000969        69507  \n",
       "1               0.000967        69507  \n",
       "2               0.000977        83460  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd685cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "936334a2",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "519e35ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09e5f4",
   "metadata": {},
   "source": [
    "# KS on PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abd42d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=30, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=95, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:38<03:12, 38.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6]\n",
      "LEN TRAINING 2145\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(bootstrap=False, max_depth=90, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=95,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [01:22<02:46, 41.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "LEN TRAINING 2519\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=10, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=89,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [02:09<02:12, 44.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "LEN TRAINING 2871\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=30,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=67,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [03:00<01:33, 46.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=110, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=30,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [03:55<00:49, 49.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "LEN TRAINING 3443\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=50, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=65,\n",
      "                       random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [04:54<00:00, 49.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Random Seed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=63,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:43<03:35, 43.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6]\n",
      "LEN TRAINING 2145\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=13,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [01:30<03:03, 45.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "LEN TRAINING 2519\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=52,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [02:19<02:21, 47.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "LEN TRAINING 2871\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=90, min_samples_leaf=2, min_samples_split=4,\n",
      "                       n_estimators=63, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [03:11<01:38, 49.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=50,\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=50,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [04:07<00:51, 51.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "LEN TRAINING 3443\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_depth=30,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=55,\n",
      "                       random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [05:18<00:00, 53.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Random Seed: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 81\u001b[0m\n\u001b[1;32m     73\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state \u001b[38;5;241m=\u001b[39m random_seed)\n\u001b[1;32m     74\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model,\n\u001b[1;32m     75\u001b[0m                                            param_distributions \u001b[38;5;241m=\u001b[39m param_dist_rf,\n\u001b[1;32m     76\u001b[0m                                            n_iter\u001b[38;5;241m=\u001b[39mN_ITER_SEARCH,\n\u001b[1;32m     77\u001b[0m                                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     78\u001b[0m                                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m random_seed)\n\u001b[0;32m---> 81\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_features_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m update_model_ks_pca \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     87\u001b[0m end_hyperparam_tunning_update \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m begin_hyperparam_tunning_update\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/AIOps_failure_prediction/venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_training_batches_list = list(range(0, num_chunks//2))\n",
    "\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "    \n",
    "    \n",
    "    print('Random Seed:', random_seed)\n",
    "    necessary_label_annotation_effort = 0\n",
    "    no_necessary_retrainings = 0\n",
    "    \n",
    "    \n",
    "    partial_roc_auc_ks_pca_model = []\n",
    "    predictions_test_ks_pca_model = []\n",
    "    \n",
    "    \n",
    "\n",
    "    total_train_fh_pca = 0\n",
    "    total_hyperparam_fh_ks_pca = 0\n",
    "    total_test_time_ks_pca = 0\n",
    "    \n",
    "    total_drift_detection_time = 0\n",
    "    total_distribution_extraction_time = 0\n",
    "    total_stat_test_time = 0\n",
    "    total_pca_time = 0\n",
    "    \n",
    "    \n",
    "    detected_drifts = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "    \n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "            current_training_batches_list = initial_training_batches_list.copy()\n",
    "            print('Initial Training Batches', current_training_batches_list)\n",
    "        \n",
    "\n",
    "        # scaler and downsampling for training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features_model = update_scaler.fit_transform(training_features)\n",
    "        training_features_model, training_labels_model = downsampling(training_features_model, training_labels)\n",
    "\n",
    "        print('LEN TRAINING', len(training_features_model))\n",
    "        \n",
    "        \n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        \n",
    "        # scaling testing features\n",
    "        testing_features_model = update_scaler.transform(testing_features)\n",
    "        testing_labels_model = testing_labels\n",
    "\n",
    "\n",
    "        # training model\n",
    "        begin_train_fh_ks_pca = time.time()\n",
    "\n",
    "\n",
    "        if(i==num_chunks//2 or need_to_retrain == 1):\n",
    "            print('RETRAINING MODEL')\n",
    "            \n",
    "            begin_train_fh_ks_pca = time.time()\n",
    "        \n",
    "            begin_hyperparam_tunning_update = time.time()\n",
    "            model = RandomForestClassifier(random_state = random_seed)\n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                                       param_distributions = param_dist_rf,\n",
    "                                                       n_iter=N_ITER_SEARCH,\n",
    "                                                       scoring='roc_auc',\n",
    "                                                       cv=4, n_jobs=1, random_state = random_seed)\n",
    "\n",
    "            \n",
    "            random_search.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            update_model_ks_pca = random_search.best_estimator_\n",
    "            \n",
    "            \n",
    "\n",
    "            end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "            \n",
    "            total_hyperparam_fh_ks_pca = total_hyperparam_fh_ks_pca + end_hyperparam_tunning_update\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            update_model_ks_pca.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            end_train_fh_ks_pca = time.time() - begin_train_fh_ks_pca\n",
    "        \n",
    "            total_train_fh_pca = total_train_fh_pca + end_train_fh_ks_pca\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data & measure testing time\n",
    "        begin_test_time_ks_pca = time.time()\n",
    "        predictions_test_updated = update_model_ks_pca.predict(testing_features_model)\n",
    "        end_test_time_ks_pca = time.time() - begin_test_time_ks_pca\n",
    "        \n",
    "        total_test_time_ks_pca = total_test_time_ks_pca + end_test_time_ks_pca\n",
    "\n",
    "        \n",
    "        # ROC AUC\n",
    "        partial_roc_auc_ks_pca_model.append(roc_auc_score(testing_labels_model, predictions_test_updated))\n",
    "        predictions_test_ks_pca_model = np.concatenate([predictions_test_ks_pca_model, predictions_test_updated])\n",
    "        \n",
    "        \n",
    "        print('Predictions Test Batch', len(predictions_test_updated))\n",
    "        print('Prediction Test All', len(predictions_test_ks_pca_model))\n",
    "        \n",
    "        \n",
    "        # Drift Detection\n",
    "        \n",
    "        need_to_retrain = 0\n",
    "        \n",
    "        print('MODEL', update_model_ks_pca)\n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        \n",
    "        # Extract PCA Features\n",
    "        \n",
    "        pca_computing_time_start = time.time()\n",
    "        \n",
    "        pca = PCA(n_components = 0.95, random_state = random_seed)\n",
    "        pca.fit(training_features_model)\n",
    "\n",
    "        df_train_features_sorted_pca = pca.transform(training_features_model)\n",
    "        df_test_features_sorted_pca = pca.transform(testing_features_model)\n",
    "        \n",
    "        pca_computing_time_end = time.time() - pca_computing_time_start\n",
    "        \n",
    "        \n",
    "        # Detect Drift\n",
    "        \n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(df_train_features_sorted_pca, df_test_features_sorted_pca)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_pca_time = total_pca_time + pca_computing_time_end\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "        \n",
    "        detected_drifts.append(drift_alert)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(drift_alert==1):\n",
    "        \n",
    "            need_to_retrain = 1\n",
    "            drift_alert = 0\n",
    "\n",
    "       \n",
    "       \n",
    "            \n",
    "            print('CHANGE OF TRAINING')\n",
    "\n",
    "            no_necessary_retrainings = no_necessary_retrainings + 1\n",
    "            necessary_label_annotation_effort = necessary_label_annotation_effort + len(testing_labels)\n",
    "\n",
    "            \n",
    "            # add new data to the training for full history approach\n",
    "            current_training_batches_list.append(i)\n",
    "                    \n",
    "            \n",
    "            training_features_list_updated = [feature_list[i] for i in current_training_batches_list]\n",
    "            training_labels_list_updated = [label_list[i] for i in current_training_batches_list]\n",
    "        \n",
    "            training_features = np.vstack(training_features_list_updated)\n",
    "            training_labels = np.hstack(training_labels_list_updated)\n",
    "\n",
    "        \n",
    "        print('Current Training Batches',current_training_batches_list)\n",
    "    \n",
    "    \n",
    "    df_results_ks_pca_model = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts_Overall',  'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Drift_Detection_Total_Time', 'PCA_Computing_time', 'Distribution_Extraction_Time', 'Statistical_Test_Time', 'Label_Costs'])\n",
    "    df_results_ks_pca_model.loc[0] = [random_seed, 'KS_PCA', str(no_necessary_retrainings)+'/'+str(len(detected_drifts)), partial_roc_auc_ks_pca_model, np.mean(partial_roc_auc_ks_pca_model), roc_auc_score(true_testing_labels, predictions_test_ks_pca_model), predictions_test_ks_pca_model, true_testing_labels, total_train_fh_pca, total_hyperparam_fh_ks_pca, total_test_time_ks_pca, detected_drifts, total_drift_detection_time, total_pca_time, total_distribution_extraction_time, total_stat_test_time, necessary_label_annotation_effort]\n",
    "    \n",
    "    \n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_ks_pca_model])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/ks_pca_fh_model_backblaze_data_green.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44d5c646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>Drifts_Overall</th>\n",
       "      <th>ROC_AUC_Batch</th>\n",
       "      <th>ROC_AUC_BATCH_MEAN</th>\n",
       "      <th>ROC_AUC_Total</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Testing_Labels</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Hyperparam_Tunning_Time</th>\n",
       "      <th>Test_Time</th>\n",
       "      <th>Drifts_Detected</th>\n",
       "      <th>Drift_Detection_Total_Time</th>\n",
       "      <th>PCA_Computing_time</th>\n",
       "      <th>Distribution_Extraction_Time</th>\n",
       "      <th>Statistical_Test_Time</th>\n",
       "      <th>Label_Costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KS_PCA</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.9224351517780277, 0.95450872656755, 0.98253...</td>\n",
       "      <td>0.963122</td>\n",
       "      <td>0.961754</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>290.710704</td>\n",
       "      <td>289.659747</td>\n",
       "      <td>0.277338</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>2.732353</td>\n",
       "      <td>0.032512</td>\n",
       "      <td>2.698766</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KS_PCA</td>\n",
       "      <td>6/6</td>\n",
       "      <td>[0.937405939683103, 0.9252054060490593, 0.9817...</td>\n",
       "      <td>0.960324</td>\n",
       "      <td>0.958769</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>315.461386</td>\n",
       "      <td>314.717954</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>2.841369</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>2.809602</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>83460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_Seed   Model Drifts_Overall  \\\n",
       "0            0  KS_PCA            6/6   \n",
       "1            1  KS_PCA            6/6   \n",
       "\n",
       "                                       ROC_AUC_Batch  ROC_AUC_BATCH_MEAN  \\\n",
       "0  [0.9224351517780277, 0.95450872656755, 0.98253...            0.963122   \n",
       "1  [0.937405939683103, 0.9252054060490593, 0.9817...            0.960324   \n",
       "\n",
       "   ROC_AUC_Total                                        Predictions  \\\n",
       "0       0.961754  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1       0.958769  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                 True_Testing_Labels  Train_Time  \\\n",
       "0  [False, False, False, False, False, False, Fal...  290.710704   \n",
       "1  [False, False, False, False, False, False, Fal...  315.461386   \n",
       "\n",
       "   Hyperparam_Tunning_Time  Test_Time     Drifts_Detected  \\\n",
       "0               289.659747   0.277338  [1, 1, 1, 1, 1, 1]   \n",
       "1               314.717954   0.201767  [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "   Drift_Detection_Total_Time  PCA_Computing_time  \\\n",
       "0                    2.732353            0.032512   \n",
       "1                    2.841369            0.030664   \n",
       "\n",
       "   Distribution_Extraction_Time  Statistical_Test_Time  Label_Costs  \n",
       "0                      2.698766               0.001036        83460  \n",
       "1                      2.809602               0.001071        83460  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8348f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4937188f",
   "metadata": {},
   "source": [
    "# DF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2eaf54d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk = pd.DataFrame()\n",
    "df_results_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ff724",
   "metadata": {},
   "source": [
    "# KS on Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fe5de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_disk_failure = ['smart_1_raw', 'smart_4_raw', 'smart_5_raw', 'smart_7_raw', 'smart_9_raw', 'smart_12_raw', 'smart_187_raw', 'smart_193_raw', 'smart_194_raw', 'smart_197_raw', 'smart_199_raw', \n",
    "                         'smart_4_raw_diff', 'smart_5_raw_diff', 'smart_9_raw_diff', 'smart_12_raw_diff', 'smart_187_raw_diff', 'smart_193_raw_diff', 'smart_197_raw_diff', 'smart_199_raw_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9ccbc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_disk_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42455308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=30, min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=95, random_state=0)\n",
      "Important Features ['smart_5_raw', 'smart_5_raw_diff', 'smart_193_raw', 'smart_9_raw', 'smart_4_raw']\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:41<03:25, 41.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6]\n",
      "LEN TRAINING 2145\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(bootstrap=False, max_depth=90, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=95,\n",
      "                       random_state=0)\n",
      "Important Features ['smart_5_raw', 'smart_5_raw_diff', 'smart_193_raw', 'smart_9_raw', 'smart_187_raw']\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [01:28<02:58, 44.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "LEN TRAINING 2519\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=10, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=89,\n",
      "                       random_state=0)\n",
      "Important Features ['smart_5_raw', 'smart_193_raw', 'smart_9_raw', 'smart_5_raw_diff', 'smart_4_raw']\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [02:16<02:19, 46.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "LEN TRAINING 2871\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=30,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=67,\n",
      "                       random_state=0)\n",
      "Important Features ['smart_5_raw', 'smart_193_raw', 'smart_9_raw', 'smart_4_raw', 'smart_5_raw_diff', 'smart_187_raw', 'smart_7_raw']\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [03:10<01:38, 49.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=110, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=30,\n",
      "                       random_state=0)\n",
      "Important Features ['smart_5_raw', 'smart_5_raw_diff', 'smart_193_raw', 'smart_9_raw', 'smart_4_raw', 'smart_7_raw']\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [04:04<00:51, 51.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "LEN TRAINING 3157\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=110, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=8, n_estimators=30,\n",
      "                       random_state=0)\n",
      "Important Features ['smart_5_raw', 'smart_5_raw_diff', 'smart_193_raw', 'smart_9_raw', 'smart_4_raw', 'smart_7_raw']\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [04:05<00:00, 40.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Batches [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Random Seed 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 13866\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=63,\n",
      "                       random_state=1)\n",
      "Important Features ['smart_5_raw', 'smart_9_raw', 'smart_193_raw', 'smart_5_raw_diff', 'smart_4_raw', 'smart_12_raw', 'smart_187_raw']\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 17%|█▋        | 1/6 [00:45<03:46, 45.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 27732\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=63,\n",
      "                       random_state=1)\n",
      "Important Features ['smart_5_raw', 'smart_9_raw', 'smart_193_raw', 'smart_5_raw_diff', 'smart_4_raw', 'smart_12_raw', 'smart_187_raw']\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 33%|███▎      | 2/6 [00:45<01:15, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 7]\n",
      "LEN TRAINING 2156\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13866\n",
      "Prediction Test All 41598\n",
      "MODEL RandomForestClassifier(criterion='entropy', max_depth=10, max_features='log2',\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=24,\n",
      "                       random_state=1)\n",
      "Important Features ['smart_5_raw', 'smart_9_raw', 'smart_5_raw_diff', 'smart_193_raw', 'smart_187_raw']\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 50%|█████     | 3/6 [01:35<01:38, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "LEN TRAINING 2508\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13955\n",
      "Prediction Test All 55553\n",
      "MODEL RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       min_samples_leaf=2, min_samples_split=4, n_estimators=52,\n",
      "                       random_state=1)\n",
      "Important Features ['smart_5_raw', 'smart_9_raw', 'smart_193_raw', 'smart_5_raw_diff', 'smart_187_raw', 'smart_12_raw', 'smart_4_raw']\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 67%|██████▋   | 4/6 [02:23<01:17, 38.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "LEN TRAINING 2794\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13954\n",
      "Prediction Test All 69507\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=110, min_samples_leaf=2,\n",
      "                       min_samples_split=8, n_estimators=66, random_state=1)\n",
      "Important Features ['smart_5_raw', 'smart_9_raw', 'smart_5_raw_diff', 'smart_193_raw', 'smart_187_raw', 'smart_4_raw', 'smart_12_raw', 'smart_7_raw']\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      " 83%|████████▎ | 5/6 [03:17<00:44, 44.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE OF TRAINING\n",
      "Current Training Batches [0, 1, 2, 3, 4, 5, 7, 8, 9, 10]\n",
      "LEN TRAINING 3080\n",
      "RETRAINING MODEL\n",
      "Predictions Test Batch 13953\n",
      "Prediction Test All 83460\n",
      "MODEL RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=50, max_features='log2',\n",
      "                       min_samples_leaf=4, n_estimators=85, random_state=1)\n",
      "Important Features ['smart_5_raw', 'smart_5_raw_diff', 'smart_9_raw', 'smart_193_raw', 'smart_187_raw', 'smart_12_raw', 'smart_4_raw', 'smart_7_raw']\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_reference = sns.distplot(np.array(reference_data)).get_lines()[0].get_data()[1]\n",
      "/var/folders/t8/w1wlk2791sx5h_whj5xs647m0000gn/T/ipykernel_1928/3917172369.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  distribution_test = sns.distplot(np.array(testing_data)).get_lines()[0].get_data()[1]\n",
      "100%|██████████| 6/6 [04:19<00:00, 43.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training Batches [0, 1, 2, 3, 4, 5, 7, 8, 9, 10]\n",
      "Random Seed 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Batches [0, 1, 2, 3, 4, 5]\n",
      "LEN TRAINING 1782\n",
      "RETRAINING MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:04<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_training_batches_list = list(range(0, num_chunks//2))\n",
    "\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "\n",
    "\n",
    "    print('Random Seed', random_seed)\n",
    "    no_necessary_retrainings = 0\n",
    "    necessary_label_annotation_effort = 0\n",
    "    \n",
    "\n",
    "    partial_roc_auc_ks_fi_model = []    \n",
    "    predictions_test_ks_fi_model = []\n",
    "    \n",
    "\n",
    "\n",
    "    total_train_fh_fi = 0\n",
    "    total_hyperparam_fh_ks_fi = 0\n",
    "    total_test_time_ks_fi = 0\n",
    "    \n",
    "    total_feature_importance_extraction_time = 0\n",
    "    total_distribution_extraction_time = 0\n",
    "    total_stat_test_time = 0\n",
    "    \n",
    "    total_drift_detection_time = 0\n",
    "\n",
    "    \n",
    "    detected_drifts = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_chunks//2, num_chunks)):\n",
    "\n",
    "\n",
    "        \n",
    "        # obtain training features and labels\n",
    "        training_features_init = np.vstack(feature_list[0: i])\n",
    "        training_labels_init = np.hstack(label_list[0//2: i])\n",
    "        \n",
    "        # init drift alert\n",
    "        drift_alert = 0\n",
    "\n",
    "        # check if it is the first batch\n",
    "        if(i==num_chunks//2):\n",
    "            training_features = training_features_init\n",
    "            training_labels = training_labels_init\n",
    "            current_training_batches_list = initial_training_batches_list.copy()\n",
    "            print('Initial Training Batches', current_training_batches_list)\n",
    "        \n",
    "\n",
    "        # scaler and downsampling for training data\n",
    "        update_scaler = StandardScaler()\n",
    "        training_features_model = update_scaler.fit_transform(training_features)\n",
    "        training_features_model, training_labels_model = downsampling(training_features_model, training_labels)\n",
    "\n",
    "        print('LEN TRAINING', len(training_features_model))\n",
    "        \n",
    "        \n",
    "        # obtain testing features and labels\n",
    "        testing_features = feature_list[i]\n",
    "        testing_labels = label_list[i]\n",
    "\n",
    "        \n",
    "        # scaling testing features\n",
    "        testing_features_model = update_scaler.transform(testing_features)\n",
    "        testing_labels_model = testing_labels\n",
    "\n",
    "\n",
    "        # training model\n",
    "        begin_train_fh_ks_fi = time.time()\n",
    "\n",
    "\n",
    "        if(i==num_chunks//2 or need_to_retrain == 1):\n",
    "            print('RETRAINING MODEL')\n",
    "            \n",
    "            begin_train_fh_ks_fi = time.time()\n",
    "        \n",
    "            begin_hyperparam_tunning_update = time.time()\n",
    "            model = RandomForestClassifier(random_state = random_seed)\n",
    "            random_search = RandomizedSearchCV(model,\n",
    "                                                       param_distributions = param_dist_rf,\n",
    "                                                       n_iter=N_ITER_SEARCH,\n",
    "                                                       scoring='roc_auc',\n",
    "                                                       cv=4, n_jobs=1, random_state = random_seed)\n",
    "\n",
    "            \n",
    "            random_search.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            update_model_ks_fi = random_search.best_estimator_\n",
    "            \n",
    "            \n",
    "\n",
    "            end_hyperparam_tunning_update = time.time() - begin_hyperparam_tunning_update\n",
    "            \n",
    "            total_hyperparam_fh_ks_fi = total_hyperparam_fh_ks_fi + end_hyperparam_tunning_update\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            update_model_ks_fi.fit(training_features_model, training_labels_model)\n",
    "            \n",
    "            end_train_fh_ks_fi = time.time() - begin_train_fh_ks_fi\n",
    "        \n",
    "            total_train_fh_fi = total_train_fh_fi + end_train_fh_ks_fi\n",
    "        \n",
    "        \n",
    "        # evaluate model on testing data\n",
    "        \n",
    "        begin_test_time_ks_fi = time.time()\n",
    "        predictions_test_updated = update_model_ks_fi.predict(testing_features_model)\n",
    "        end_test_time_ks_fi = time.time() - begin_test_time_ks_fi\n",
    "        \n",
    "        total_test_time_ks_fi = total_test_time_ks_fi + end_test_time_ks_fi\n",
    "        \n",
    "\n",
    "        partial_roc_auc_ks_fi_model.append(roc_auc_score(testing_labels_model, predictions_test_updated))\n",
    "        predictions_test_ks_fi_model = np.concatenate([predictions_test_ks_fi_model, predictions_test_updated])\n",
    "        \n",
    "        \n",
    "        print('Predictions Test Batch', len(predictions_test_updated))\n",
    "        print('Prediction Test All', len(predictions_test_ks_fi_model))\n",
    "        \n",
    "        \n",
    "        # Drift Detection\n",
    "        \n",
    "        need_to_retrain = 0\n",
    "        \n",
    "        print('MODEL', update_model_ks_fi)\n",
    "        \n",
    "        drift_time_start = time.time()\n",
    "        \n",
    "        # Extract Most Important Features\n",
    "        feature_importance_extraction_start = time.time()\n",
    "        important_features = important_features_extraction(update_model_ks_fi, features_disk_failure)\n",
    "        print('Important Features', important_features)\n",
    "        print(len(important_features))\n",
    "\n",
    "        # filter non-important features from train and test\n",
    "\n",
    "        training_important_features_model = filtering_non_important_features(training_features_model, features_disk_failure, important_features)\n",
    "        testing_important_features_model = filtering_non_important_features(testing_features_model, features_disk_failure, important_features)\n",
    "\n",
    "        feature_importance_extraction_end = time.time() - feature_importance_extraction_start\n",
    "        \n",
    "        \n",
    "        # Detect Drift\n",
    "        \n",
    "        drift_alert, distribution_extraction_time, ks_test_time = ks_drift_detection(training_important_features_model, testing_important_features_model)\n",
    "        drift_time_end = time.time() - drift_time_start\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        total_distribution_extraction_time = total_distribution_extraction_time + distribution_extraction_time\n",
    "        total_stat_test_time = total_stat_test_time + ks_test_time\n",
    "        total_feature_importance_extraction_time = total_feature_importance_extraction_time + feature_importance_extraction_end\n",
    "        total_drift_detection_time = total_drift_detection_time + drift_time_end\n",
    "        \n",
    "        \n",
    "        detected_drifts.append(drift_alert)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(drift_alert==1):\n",
    "        \n",
    "            need_to_retrain = 1\n",
    "            drift_alert = 0\n",
    "\n",
    "       \n",
    "       \n",
    "            \n",
    "            print('CHANGE OF TRAINING')\n",
    "\n",
    "            no_necessary_retrainings = no_necessary_retrainings + 1\n",
    "            necessary_label_annotation_effort = necessary_label_annotation_effort + len(testing_labels)\n",
    "            \n",
    "            # add new data to the training for full history approach\n",
    "            current_training_batches_list.append(i)\n",
    "            \n",
    "            training_features_list_updated = [feature_list[i] for i in current_training_batches_list]\n",
    "            training_labels_list_updated = [label_list[i] for i in current_training_batches_list]\n",
    "        \n",
    "            training_features = np.vstack(training_features_list_updated)\n",
    "            training_labels = np.hstack(training_labels_list_updated)\n",
    "\n",
    "        \n",
    "        print('Current Training Batches',current_training_batches_list)\n",
    "    \n",
    "    \n",
    "    df_results_ks_fi_model = pd.DataFrame(columns=['Random_Seed', 'Model', 'Drifts_Overall',  'ROC_AUC_Batch', 'ROC_AUC_BATCH_MEAN', 'ROC_AUC_Total', 'Predictions', 'True_Testing_Labels', 'Train_Time', 'Hyperparam_Tunning_Time', 'Test_Time', 'Drifts_Detected', 'Drift_Detection_Total_Time', 'FI_Extraction_Time', 'Distribution_Extraction_Time', 'Statistical_Test_Time', 'Label_Costs'])\n",
    "    df_results_ks_fi_model.loc[0] = [random_seed, 'KS_FI', str(no_necessary_retrainings)+'/'+str(len(detected_drifts)), partial_roc_auc_ks_fi_model, np.mean(partial_roc_auc_ks_fi_model), roc_auc_score(true_testing_labels, predictions_test_ks_fi_model), predictions_test_ks_fi_model, true_testing_labels, total_train_fh_fi, total_hyperparam_fh_ks_fi, total_test_time_ks_fi, detected_drifts, total_drift_detection_time, total_feature_importance_extraction_time, total_distribution_extraction_time, total_stat_test_time, necessary_label_annotation_effort]\n",
    "    \n",
    "    \n",
    "    df_results_disk = pd.concat([df_results_disk, df_results_ks_fi_model])\n",
    "    df_results_disk = df_results_disk.reset_index(drop=True)\n",
    "    df_results_disk.to_csv('./results/ks_FI_fh_model_backblaze_data_green.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d7ff0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random_Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>Drifts_Overall</th>\n",
       "      <th>ROC_AUC_Batch</th>\n",
       "      <th>ROC_AUC_BATCH_MEAN</th>\n",
       "      <th>ROC_AUC_Total</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Testing_Labels</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Hyperparam_Tunning_Time</th>\n",
       "      <th>Test_Time</th>\n",
       "      <th>Drifts_Detected</th>\n",
       "      <th>Drift_Detection_Total_Time</th>\n",
       "      <th>FI_Extraction_Time</th>\n",
       "      <th>Distribution_Extraction_Time</th>\n",
       "      <th>Statistical_Test_Time</th>\n",
       "      <th>Label_Costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KS_FI</td>\n",
       "      <td>4/6</td>\n",
       "      <td>[0.9224351517780277, 0.95450872656755, 0.98253...</td>\n",
       "      <td>0.957259</td>\n",
       "      <td>0.956257</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>242.211063</td>\n",
       "      <td>241.291457</td>\n",
       "      <td>0.269554</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0]</td>\n",
       "      <td>2.162277</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>2.123311</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>55553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KS_FI</td>\n",
       "      <td>4/6</td>\n",
       "      <td>[0.937405939683103, 0.9539303575681284, 0.9664...</td>\n",
       "      <td>0.965515</td>\n",
       "      <td>0.964043</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>256.807663</td>\n",
       "      <td>255.915696</td>\n",
       "      <td>0.271374</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0]</td>\n",
       "      <td>2.499732</td>\n",
       "      <td>0.037984</td>\n",
       "      <td>2.460605</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>55641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random_Seed  Model Drifts_Overall  \\\n",
       "0            0  KS_FI            4/6   \n",
       "1            1  KS_FI            4/6   \n",
       "\n",
       "                                       ROC_AUC_Batch  ROC_AUC_BATCH_MEAN  \\\n",
       "0  [0.9224351517780277, 0.95450872656755, 0.98253...            0.957259   \n",
       "1  [0.937405939683103, 0.9539303575681284, 0.9664...            0.965515   \n",
       "\n",
       "   ROC_AUC_Total                                        Predictions  \\\n",
       "0       0.956257  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1       0.964043  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                 True_Testing_Labels  Train_Time  \\\n",
       "0  [False, False, False, False, False, False, Fal...  242.211063   \n",
       "1  [False, False, False, False, False, False, Fal...  256.807663   \n",
       "\n",
       "   Hyperparam_Tunning_Time  Test_Time     Drifts_Detected  \\\n",
       "0               241.291457   0.269554  [1, 1, 1, 1, 0, 0]   \n",
       "1               255.915696   0.271374  [0, 1, 1, 1, 1, 0]   \n",
       "\n",
       "   Drift_Detection_Total_Time  FI_Extraction_Time  \\\n",
       "0                    2.162277            0.037782   \n",
       "1                    2.499732            0.037984   \n",
       "\n",
       "   Distribution_Extraction_Time  Statistical_Test_Time  Label_Costs  \n",
       "0                      2.123311               0.001153        55553  \n",
       "1                      2.460605               0.001109        55641  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b7447",
   "metadata": {},
   "source": [
    "!!!! all tested, clean code and push on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd36120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
